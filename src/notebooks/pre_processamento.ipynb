{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mATEhUHWTvDp"
      },
      "source": [
        "## Conectando ao Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqwe4P_CLSrJ",
        "outputId": "93880e6c-e831-410c-97af-5ef1f17e29b3"
      },
      "outputs": [],
      "source": [
        "# Mounting GDrive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSykBC-bshpp"
      },
      "source": [
        "## Import das Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "ARib91W-L-fn",
        "outputId": "aab08946-f186-4b62-c970-c7c9ee4ea4e4"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BSn5gXSo6RFH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import rasterio\n",
        "from rasterio.enums import Resampling\n",
        "import shutil\n",
        "from PIL import Image\n",
        "import skimage.io as io\n",
        "import skimage.transform as trans\n",
        "import numpy as np\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras import backend as keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYptLhlJTpoL"
      },
      "source": [
        "##Seleção de parâmetros\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohDHVH4QTnk9",
        "outputId": "ae15c36d-9391-4129-abc5-61ab894a8715"
      },
      "outputs": [],
      "source": [
        "#@title Configuração do Processamento de Imagem { run: \"auto\", display-mode: \"form\" }\n",
        "\n",
        "#@markdown ### Seleção de Tipos de Imagem:\n",
        "marked_rgb = True #@param {type:\"boolean\"}\n",
        "rgb = True #@param {type:\"boolean\"}\n",
        "png = True #@param {type:\"boolean\"}\n",
        "ndvi = True #@param {type:\"boolean\"}\n",
        "gndvi = True #@param {type:\"boolean\"}\n",
        "original_tif = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Filtros de Pré-processamento:\n",
        "calibration = True #@param {type:\"boolean\"}\n",
        "atmospheric_correction = True #@param {type:\"boolean\"}\n",
        "remove_clouds = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Dimensões da Imagem (Altura e Largura são iguais):\n",
        "image_dimension = 300 # @param {type:\"slider\", min:300, max:1200, step:10}\n",
        "\n",
        "#@markdown ### Técnicas de Data Augmentation:\n",
        "flip_horizontal = True #@param {type:\"boolean\"}\n",
        "rotation = True #@param {type:\"boolean\"}\n",
        "scaling = True #@param {type:\"boolean\"}\n",
        "shear = True #@param {type:\"boolean\"}\n",
        "brightness_adjustment = True #@param {type:\"boolean\"}\n",
        "none_aug = False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown ### Técnica de Normalização:\n",
        "normalization_technique = \"Max Abs Scaling\" #@param [\"Min-Max Scaling\", \"Z-Score\", \"Max Abs Scaling\", \"Robust Scaling\", \"None\"] {type:\"string\"}\n",
        "\n",
        "#@markdown ### Divisão de Dados de Treino/Teste (% para Treino):\n",
        "training_percentage = 80 #@param {type:\"slider\", min:10, max:90, step:5}\n",
        "\n",
        "# Compila a lista de tipos de imagem selecionados\n",
        "image_types = []\n",
        "if marked_rgb: image_types.append(\"Marked RGB\")\n",
        "if rgb: image_types.append(\"RGB\")\n",
        "if png: image_types.append(\"PNG\")\n",
        "if ndvi: image_types.append(\"NDVI\")\n",
        "if gndvi: image_types.append(\"GNDVI\")\n",
        "if original_tif: image_types.append(\"TIFF\")\n",
        "image_types.append(\"Binary Mask\")\n",
        "\n",
        "# Compila a lista de técnicas de data augmentation selecionadas\n",
        "data_augmentation = []\n",
        "if flip_horizontal: data_augmentation.append(\"Flip Horizontal\")\n",
        "if rotation: data_augmentation.append(\"Rotation\")\n",
        "if scaling: data_augmentation.append(\"Scaling\")\n",
        "if shear: data_augmentation.append(\"Shear\")\n",
        "if brightness_adjustment: data_augmentation.append(\"Brightness Adjustment\")\n",
        "if none_aug: data_augmentation = [\"None\"]  # Prioriza 'None' se selecionado\n",
        "\n",
        "# Calcula a porcentagem de teste com base na porcentagem de treino\n",
        "test_percentage = 100 - training_percentage\n",
        "\n",
        "print(f\"Tipos de Imagem Selecionados: {image_types}\")\n",
        "print(f\"Técnicas de Data Augmentation: {data_augmentation}\")\n",
        "print(f\"Calibração Radiométrica: {'Ativada' if calibration else 'Desativada'}\")\n",
        "print(f\"Correção Atmosférica: {'Ativada' if atmospheric_correction else 'Desativada'}\")\n",
        "print(f\"Dimensões da Imagem: {image_dimension} x {image_dimension}\")\n",
        "print(f\"Técnica de Normalização: {normalization_technique}\")\n",
        "print(f\"Porcentagem de Treino: {training_percentage}%\")\n",
        "print(f\"Porcentagem de Teste: {test_percentage}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBmWgHklsqVt"
      },
      "source": [
        "## Preparação dos Dados de Treino"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIZjTk2TtlsW"
      },
      "source": [
        "Separação dos dados para treino do modelo. A ideia foi separar em diretórios distintos, cada variável vai armazenar o diretório com um tipo específico de imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhxEN-mDMaUG"
      },
      "outputs": [],
      "source": [
        "addressDSmain = '/content/drive/MyDrive/modulo10/data/dataset_inteli'\n",
        "\n",
        "# Dicionário para mapear nomes de diretório aos seus respectivos sufixos\n",
        "directory_suffixes = {\n",
        "    \"Marked RGB\": 'marked_rgbs',\n",
        "    \"RGB\": 'rgbs',\n",
        "    \"TIFF\": 'tci_tifs',\n",
        "    \"PNG\": 'tci_pngs',\n",
        "    \"NDVI\": 'ndvi',\n",
        "    \"GNDVI\": 'gndvi',\n",
        "    \"Binary Mask\": 'masks'\n",
        "}\n",
        "\n",
        "# Dicionário com diretório e caminhos\n",
        "directory_map = {\n",
        "    key: os.path.join(addressDSmain, suffix)\n",
        "    for key, suffix in directory_suffixes.items()\n",
        "    if key in image_types\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mcMUHNFqim0o"
      },
      "outputs": [],
      "source": [
        "def process_files_in_directory(directory_path, process_function):\n",
        "    \"\"\"Processa arquivos dentro de um diretório e seus subdiretórios com uma função especificada.\"\"\"\n",
        "    for root, dirs, files in os.walk(directory_path):\n",
        "        for file in files:\n",
        "            if file.endswith('.tif'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                process_function(file_path, file_path)  # Substitui o arquivo original\n",
        "\n",
        "\n",
        "\n",
        "def calibrar_radiometricamente(image_path, output_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        # Converte a imagem para um array numpy para processamento\n",
        "        img_array = np.array(img)\n",
        "        # Simulando a calibração radiométrica multiplicando cada pixel por 1.05\n",
        "        calibrated_array = img_array * 1.05\n",
        "        calibrated_array = np.clip(calibrated_array, 0, 255)  # Assegura que os valores estão entre 0 e 255\n",
        "        # Converte de volta para uma imagem\n",
        "        calibrated_img = Image.fromarray(calibrated_array.astype('uint8'))\n",
        "        calibrated_img.save(output_path)\n",
        "\n",
        "def corrigir_atmosfericamente(image_path, output_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        # Converte a imagem para um array numpy para processamento\n",
        "        img_array = np.array(img)\n",
        "        # Simulando a correção atmosférica ajustando o contraste da imagem\n",
        "        # Aumentando o contraste em 10%\n",
        "        contrast_factor = 1.1\n",
        "        mean = np.mean(img_array)\n",
        "        corrected_array = (img_array - mean) * contrast_factor + mean\n",
        "        corrected_array = np.clip(corrected_array, 0, 255)  # Assegura que os valores estão entre 0 e 255\n",
        "        # Converte de volta para uma imagem\n",
        "        corrected_img = Image.fromarray(corrected_array.astype('uint8'))\n",
        "        corrected_img.save(output_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2FqoXq9lDtb"
      },
      "outputs": [],
      "source": [
        "if \"NDVI\" or \"GNDVI\" in directory_map:\n",
        "  # Caminho para as imagens TIF dentro de subdiretórios em \"images\"\n",
        "  tif_path = os.path.join(addressDSmain, \"images\")\n",
        "\n",
        "  # Processa todas as imagens TIF para calibração radiométrica e correção atmosférica\n",
        "  if calibration:\n",
        "    process_files_in_directory(tif_path, calibrar_radiometricamente)\n",
        "\n",
        "  if atmospheric_correction:\n",
        "    process_files_in_directory(tif_path, corrigir_atmosfericamente)\n",
        "\n",
        "if \"TIFF\" in directory_map:\n",
        "  # Caminho para as imagens TIF dentro de subdiretórios em \"images\"\n",
        "  tif_path = directory_map[\"TIFF\"]\n",
        "\n",
        "  # Processa todas as imagens TIF para calibração radiométrica e correção atmosférica\n",
        "  if calibration:\n",
        "    process_files_in_directory(tif_path, calibrar_radiometricamente)\n",
        "\n",
        "  if atmospheric_correction:\n",
        "    process_files_in_directory(tif_path, corrigir_atmosfericamente)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ebWru1yI5R_"
      },
      "outputs": [],
      "source": [
        "treinamento_images = {}\n",
        "\n",
        "def band_number(filename):\n",
        "    parts = filename.split('.')[0].split('b')\n",
        "    if len(parts) > 1:\n",
        "        try:\n",
        "            number_part = parts[1]\n",
        "            if number_part.endswith('a'):\n",
        "                return int(number_part[:-1]) + 0.1\n",
        "            return int(number_part)\n",
        "        except ValueError:\n",
        "            return float('inf')\n",
        "    return float('inf')\n",
        "\n",
        "\n",
        "image_directories = sorted(os.listdir(addressDSmain+\"/images\"))\n",
        "\n",
        "for directory in image_directories:\n",
        "    directory_path = os.path.join(addressDSmain+\"/images\", directory)\n",
        "\n",
        "\n",
        "    if os.path.isdir(directory_path):\n",
        "\n",
        "        tif_files = sorted([f for f in os.listdir(directory_path) if f.endswith('.tif')], key=band_number)\n",
        "\n",
        "        treinamento_images[directory] = [os.path.join(directory_path, f) for f in tif_files]\n",
        "\n",
        "\n",
        "def get_band_paths(directory_files, band_nir='8', band_red='4', band_green='3'):\n",
        "    \"\"\"\n",
        "    Retorna os caminhos das bandas NIR, Red e Green para cálculos de índices.\n",
        "\n",
        "    Args:\n",
        "    directory_files (list): Lista de todos os arquivos em um diretório.\n",
        "    band_nir (str): Sufixo da banda NIR no nome do arquivo (padrão '8' para b8).\n",
        "    band_red (str): Sufijo da banda Red no nome do arquivo (padrão '4' para b4).\n",
        "    band_green (str): Sufixo da banda Green no nome do arquivo (padrão '3' para b3).\n",
        "\n",
        "    Returns:\n",
        "    tuple: Contém os caminhos dos arquivos para as bandas NIR, Red e Green.\n",
        "          Cada elemento pode ser None se a banda correspondente não for encontrada.\n",
        "    \"\"\"\n",
        "    nir_path = [file for file in directory_files if f\"b{band_nir}.tif\" in file]\n",
        "    red_path = [file for file in directory_files if f\"b{band_red}.tif\" in file]\n",
        "    green_path = [file for file in directory_files if f\"b{band_green}.tif\" in file]\n",
        "\n",
        "\n",
        "    return nir_path[0] if nir_path else None, \\\n",
        "          red_path[0] if red_path else None, \\\n",
        "          green_path[0] if green_path else None\n",
        "\n",
        "\n",
        "def calculate_and_save_index(nir_band_path, other_band_path, index_type, output_path):\n",
        "    \"\"\"Calcula e salva um índice específico (NDVI/GNDVI).\"\"\"\n",
        "    with rasterio.open(nir_band_path) as nir_src, rasterio.open(other_band_path) as other_src:\n",
        "        nir = nir_src.read(1, resampling=Resampling.bilinear)\n",
        "        other_band = other_src.read(1, resampling=Resampling.bilinear)\n",
        "        index = (nir.astype(float) - other_band.astype(float)) / (nir + other_band + 1e-10)\n",
        "\n",
        "\n",
        "        profile = nir_src.profile\n",
        "        profile.update(dtype=rasterio.float32, count=1, compress='lzw')\n",
        "\n",
        "        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "        with rasterio.open(output_path, 'w', **profile) as dst:\n",
        "            dst.write(index.astype(rasterio.float32), 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cJecOAGJgdW",
        "outputId": "bd9ff721-3b76-4da9-f895-767906c67a1c"
      },
      "outputs": [],
      "source": [
        "\n",
        "def ensure_directory_clean(directory_path):\n",
        "    \"\"\"Garante que o diretório seja apagado se existir e criado limpo.\"\"\"\n",
        "    if os.path.exists(directory_path):\n",
        "        shutil.rmtree(directory_path)\n",
        "    os.makedirs(directory_path)\n",
        "\n",
        "if \"NDVI\" in directory_map:\n",
        "    ndvi_directory = directory_map[\"NDVI\"]\n",
        "    ensure_directory_clean(ndvi_directory)\n",
        "\n",
        "    def process_ndvi(treinamento_images, base_path):\n",
        "        \"\"\"Processa e salva NDVI para cada diretório de imagem.\"\"\"\n",
        "        for directory, files in treinamento_images.items():\n",
        "            nir_path, red_path, _ = get_band_paths(files)\n",
        "            if nir_path and red_path:\n",
        "                output_path = os.path.join(ndvi_directory, f'{directory}_NDVI.tif')\n",
        "                calculate_and_save_index(nir_path, red_path, 'NDVI', output_path)\n",
        "\n",
        "    process_ndvi(treinamento_images, addressDSmain)\n",
        "\n",
        "if \"GNDVI\" in directory_map:\n",
        "    gndvi_directory = directory_map[\"GNDVI\"]\n",
        "    ensure_directory_clean(gndvi_directory)\n",
        "\n",
        "    def process_gndvi(treinamento_images, base_path):\n",
        "        \"\"\"Processa e salva GNDVI para cada diretório de imagem.\"\"\"\n",
        "        for directory, files in treinamento_images.items():\n",
        "            nir_path, _, green_path = get_band_paths(files)\n",
        "            if nir_path and green_path:\n",
        "                output_path = os.path.join(gndvi_directory, f'{directory}_GNDVI.tif')\n",
        "                calculate_and_save_index(nir_path, green_path, 'GNDVI', output_path)\n",
        "\n",
        "    process_gndvi(treinamento_images, addressDSmain)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZycATCy-YNo8",
        "outputId": "1425e2d8-f32e-4015-f4c0-0176d7d6c09f"
      },
      "outputs": [],
      "source": [
        "directory_destiny = os.path.join(addressDSmain, 'imagens_unificadas')\n",
        "\n",
        "ensure_directory_clean(directory_destiny)\n",
        "\n",
        "def copiar_e_renomear(diretorio_origem, prefixo):\n",
        "    arquivos = sorted(os.listdir(diretorio_origem))\n",
        "    for idx, arquivo in enumerate(arquivos):\n",
        "        arquivo_origem = os.path.join(diretorio_origem, arquivo)\n",
        "        novo_nome = f\"{prefixo}_{idx}{os.path.splitext(arquivo)[1]}\"\n",
        "        arquivo_destino = os.path.join(directory_destiny, novo_nome)\n",
        "        shutil.copy(arquivo_origem, arquivo_destino)\n",
        "\n",
        "for prefixo, diretorio in directory_map.items():\n",
        "    copiar_e_renomear(diretorio, prefixo)\n",
        "\n",
        "print(\"Arquivos copiados e renomeados com sucesso.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uO8sm6Wo7VH"
      },
      "outputs": [],
      "source": [
        "# def ensure_directory(directory):\n",
        "#     if not os.path.exists(directory):\n",
        "#         os.makedirs(directory)\n",
        "#     else:\n",
        "#         print(f\"Directory '{directory}' already exists.\")\n",
        "\n",
        "# def data_augmentation(unified_directory, augmented_directory, image_dimension, rotation=True, scaling=True, shear=True, flip_horizontal=True):\n",
        "#     ensure_directory(augmented_directory)\n",
        "\n",
        "#     datagen = ImageDataGenerator(\n",
        "#         rotation_range=90 if rotation else 0,\n",
        "#         shear_range=0.2 if shear else 0.0,\n",
        "#         zoom_range=0.2 if scaling else 0.0,\n",
        "#         horizontal_flip=flip_horizontal,\n",
        "#         fill_mode='nearest'\n",
        "#     )\n",
        "\n",
        "#     for filename in os.listdir(unified_directory):\n",
        "#         if filename.endswith(\".tif\") or filename.endswith(\".png\"):\n",
        "#             image_path = os.path.join(unified_directory, filename)\n",
        "#             print(f\"Processing file: {filename}\")\n",
        "#             try:\n",
        "#                 image = load_img(image_path, target_size=(image_dimension, image_dimension))\n",
        "#                 x = img_to_array(image)\n",
        "#                 x = x.reshape((1,) + x.shape)\n",
        "\n",
        "#                 name, ext = os.path.splitext(filename)\n",
        "\n",
        "#                 i = 0\n",
        "#                 for batch in datagen.flow(x, batch_size=1):\n",
        "#                     i += 1\n",
        "#                     new_name = f\"augmented_{name}_{i}{ext}\"\n",
        "#                     save_path = os.path.join(augmented_directory, new_name)\n",
        "#                     img_to_save = Image.fromarray(batch[0].astype('uint8'))\n",
        "#                     img_to_save.save(save_path)\n",
        "#                     if i >= 5:\n",
        "#                         break\n",
        "\n",
        "#             except UnidentifiedImageError:\n",
        "#                 print(f\"Error: Cannot identify image file {image_path}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Unexpected error occurred with file {image_path}: {e}\")\n",
        "\n",
        "# def count_images(directory):\n",
        "#     count = len([file for file in os.listdir(directory) if file.endswith(\".tif\") or file.endswith(\".png\")])\n",
        "#     return count\n",
        "\n",
        "# addressDSmain = '/content/drive/MyDrive/modulo10/data/dataset_inteli'\n",
        "\n",
        "# unified_directory = os.path.join(addressDSmain, \"imagens_unificadas\")\n",
        "# augmented_directory = os.path.join(addressDSmain, \"augmented_images\")\n",
        "# image_dimension = 224\n",
        "\n",
        "# data_augmentation(unified_directory, augmented_directory, image_dimension)\n",
        "\n",
        "# print(\"Data augmentation completed\")\n",
        "\n",
        "# num_augmented_images = count_images(augmented_directory)\n",
        "# print(f\"Number of augmented images: {num_augmented_images}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0GgLVB6fI_T"
      },
      "source": [
        "## Data Augmentation\n",
        "\n",
        "O objetivo deste data augmentation foi gerar novas imagens de máscaras (masks) para as imagens de satélite do dataset do cliente. Essencialmente, a mask foi definida como o target. Assim, para cada imagem aumentada, foi gerada uma máscara correspondente, permitindo que o modelo aprenda a segmentar corretamente.\n",
        "\n",
        "A ideia é se inicia em renomear as imagens que vão ser utilizadas para treinamento do modelo, para o mesmo nome das suas correspondentes a masks, para depois realizar o mesmo método de augmentation para as imagens de treino.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-fW_j4ymwvm",
        "outputId": "1d37c8b9-9cbf-4c2e-dc23-7918b3f6463a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def rename_images(directory):\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(\".tif\") or filename.endswith(\".png\"):\n",
        "            # Extrair o número antes do primeiro sublinhado\n",
        "            new_name = filename.split('_')[0] + os.path.splitext(filename)[1]\n",
        "            old_path = os.path.join(directory, filename)\n",
        "            new_path = os.path.join(directory, new_name)\n",
        "            os.rename(old_path, new_path)\n",
        "            print(f\"Renamed '{filename}' to '{new_name}'\")\n",
        "\n",
        "# Diretório onde estão as imagens marked_rgb\n",
        "marked_rgb_directory = '/content/drive/MyDrive/modulo10/data/dataset_inteli/rgbs'\n",
        "\n",
        "# Renomear as imagens\n",
        "rename_images(marked_rgb_directory)\n",
        "\n",
        "print(\"Renaming completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUZKEzPk9iJ2",
        "outputId": "c12e3832-b100-4b9f-f4cb-b9289fb5b847"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "\n",
        "# Aplicando o mesmo data augmentation para as máscaras e imagens de satélite\n",
        "def data_augmentation_for_pairs(marked_rgb_directory, masks_directory, image_dimension, rotation=True, scaling=True, shear=True, flip_horizontal=True):\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=90 if rotation else 0,\n",
        "        shear_range=0.2 if shear else 0.0,\n",
        "        zoom_range=0.2 if scaling else 0.0,\n",
        "        horizontal_flip=flip_horizontal,\n",
        "        fill_mode='nearest'\n",
        "    )\n",
        "\n",
        "    for filename in os.listdir(marked_rgb_directory):\n",
        "        if filename.endswith(\".tif\") or filename.endswith(\".png\"):\n",
        "            image_path_rgb = os.path.join(marked_rgb_directory, filename)\n",
        "            image_path_mask = os.path.join(masks_directory, filename)\n",
        "            print(f\"Processing file: {filename}\")\n",
        "\n",
        "            try:\n",
        "                image_rgb = load_img(image_path_rgb, target_size=(image_dimension, image_dimension))\n",
        "                image_mask = load_img(image_path_mask, target_size=(image_dimension, image_dimension))\n",
        "\n",
        "                x_rgb = img_to_array(image_rgb)\n",
        "                x_mask = img_to_array(image_mask)\n",
        "\n",
        "                x_rgb = x_rgb.reshape((1,) + x_rgb.shape)\n",
        "                x_mask = x_mask.reshape((1,) + x_mask.shape)\n",
        "\n",
        "                name, ext = os.path.splitext(filename)\n",
        "\n",
        "                i = 0\n",
        "                rgb_gen = datagen.flow(x_rgb, batch_size=1, seed=42)\n",
        "                mask_gen = datagen.flow(x_mask, batch_size=1, seed=42)\n",
        "\n",
        "                for (batch_rgb, batch_mask) in zip(rgb_gen, mask_gen):\n",
        "                    i += 1\n",
        "                    new_name = f\"{name}_{i}{ext}\"\n",
        "                    save_path_rgb = os.path.join(marked_rgb_directory, new_name)\n",
        "                    save_path_mask = os.path.join(masks_directory, new_name)\n",
        "\n",
        "                    img_to_save_rgb = Image.fromarray(batch_rgb[0].astype('uint8'))\n",
        "                    img_to_save_mask = Image.fromarray(batch_mask[0].astype('uint8'))\n",
        "\n",
        "                    img_to_save_rgb.save(save_path_rgb)\n",
        "                    img_to_save_mask.save(save_path_mask)\n",
        "\n",
        "                    if i >= 50:\n",
        "                        break\n",
        "\n",
        "            except UnidentifiedImageError:\n",
        "                print(f\"Error: Cannot identify image file {image_path_rgb} or {image_path_mask}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Unexpected error occurred with file {filename}: {e}\")\n",
        "\n",
        "# Diretórios de entrada\n",
        "addressDSmain = '/content/drive/MyDrive/modulo10/data/dataset_inteli'\n",
        "marked_rgb_directory = os.path.join(addressDSmain, \"rgbs\")\n",
        "masks_directory = os.path.join(addressDSmain, \"masks\")\n",
        "image_dimension = 1200\n",
        "\n",
        "# Aplicar data augmentation\n",
        "data_augmentation_for_pairs(marked_rgb_directory, masks_directory, image_dimension)\n",
        "\n",
        "print(\"Data augmentation completed\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pZYMP2g-iteD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "def ensure_directory_exists(directory):\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "def normalize_images(image_directory, normalized_directory, image_dimension, normalization_technique):\n",
        "    # Verify if the diretory exists\n",
        "    ensure_directory_exists(normalized_directory)\n",
        "\n",
        "    for filename in os.listdir(image_directory):\n",
        "        if filename.endswith(\".tif\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(image_directory, filename)\n",
        "            image = load_img(image_path, target_size=(image_dimension, image_dimension))\n",
        "            x = img_to_array(image)\n",
        "\n",
        "            if normalization_technique == \"Min-Max Scaling\":\n",
        "                min_val, max_val = np.min(x), np.max(x)\n",
        "                if max_val - min_val != 0:\n",
        "                    x = (x - min_val) / (max_val - min_val)\n",
        "                else:\n",
        "                    x = np.zeros_like(x)\n",
        "\n",
        "            elif normalization_technique == \"Z-Score\":\n",
        "                mean, std = np.mean(x), np.std(x)\n",
        "                if std != 0:\n",
        "                    x = (x - mean) / std\n",
        "                else:\n",
        "                    x = np.zeros_like(x)\n",
        "\n",
        "            elif normalization_technique == \"Max Abs Scaling\":\n",
        "                max_abs_val = np.max(np.abs(x))\n",
        "                if max_abs_val != 0:\n",
        "                    x = x / max_abs_val\n",
        "                else:\n",
        "                    x = np.zeros_like(x)\n",
        "\n",
        "            elif normalization_technique == \"Robust Scaling\":\n",
        "                median, iqr = np.median(x), np.percentile(x, 75) - np.percentile(x, 25)\n",
        "                if iqr != 0:\n",
        "                    x = (x - median) / iqr\n",
        "                else:\n",
        "                    x = np.zeros_like(x)\n",
        "\n",
        "            x = (x * 255).astype(np.uint8)\n",
        "            img = tf.keras.preprocessing.image.array_to_img(x)\n",
        "\n",
        "            # Alterar o nome do arquivo para incluir 'normalized_' no início\n",
        "            name, ext = os.path.splitext(filename)\n",
        "            new_filename = f\"normalized_{name}{ext}\"\n",
        "\n",
        "            img.save(os.path.join(normalized_directory, new_filename))\n",
        "\n",
        "# Main directory\n",
        "addressDSmain = '/content/drive/MyDrive/modulo10/data/dataset_inteli'\n",
        "\n",
        "unified_directory = os.path.join(addressDSmain, \"imagens_unificadas\")\n",
        "normalized_directory = os.path.join(addressDSmain, \"imagens_normalizadas\")\n",
        "image_dimension = 224\n",
        "\n",
        "normalize_images(unified_directory, normalized_directory, image_dimension, normalization_technique)\n",
        "\n",
        "print(\"Normalização concluída\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "ePCiv_EOjIeW",
        "outputId": "e2aa7ef2-cf76-4764-9bb0-c9a97593db9f"
      },
      "outputs": [],
      "source": [
        "image_path = '/content/drive/MyDrive/modulo10/data/dataset_inteli/rgbs/575_1.png'\n",
        "\n",
        "with rasterio.open(image_path) as src:\n",
        "    image_data = src.read(1)\n",
        "\n",
        "plt.imshow(image_data, cmap='gray')\n",
        "plt.axis('off')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
